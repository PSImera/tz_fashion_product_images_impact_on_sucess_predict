# Отчёт о проведённом анализ влияния фотографий товаров на успешность продаж

Цель проекта — разработать прототип модели, которая оценивает, насколько изображение товара связано с его успешностью на маркетплейсе. Модель должна помочь понять, играют ли визуальные характеристики ключевую роль в привлечении покупателей и повышении интереса к продукту

Этапы:
- Загрузка и предварительная обработка данных
- Подготовка и отбор табличных признаков
- Формирование бинарного таргета успешности товара на основании синтетической прокси метрики (топ 20%)
- Извлечение визуальных признаков из изображений
- Обучение и сравнение моделей на разных наборах признаков: Табличные, Визуальные, Комбинированные
- Анализ качества
- кластеризация изображений

## Загрузка и предварительная обработка данных

Датасет был скачан c [kaggle](https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset) на локальный пк и проанализированы данные из csv таблицы и из файлов json. Данные из csv читались с ошибками (22 строки не считались), а в json было значительно больше полезной информации сверх той что была в csv, а те колонки, что дублировались, совпадали на 100%, поэтому решено было исполбзовать датасет полученный из json файлов.

С Json файлов были считаны следующие признаки:
- Дублирующиеся в csv таблице (`id`, 
`masterCategory`, `subCategory`, `articleType`,
`baseColour`, `gender`, `season`, `year`, `usage`, `productDisplayName`
- дополнительные категориальные признаки (`brandName`, `ageGroup`, `fashionType`)
- дополнительные числовые признаки (`price`, `discountedPrice`, `myntraRating`)
- дополнительные булевы признаки (`isFragile`, `isTryAndBuyEnabled`, `isHazmat`, `isJewellery`, `isReturnable`, `isExchangeable`, `active`, `socialSharingEnabled`, `pickupEnabled`, `isLarge`, `codEnabled`)
- из общего количества размеров и размеров со статусом `available` сформирован признак `size_availability`

В датасете присутствовали пропуски, часть из которых были заполнены, а остальные строки с пропусками были удалены:
- `fashionType` 3 пропуска удалено
- `baseColour` 15 пропусков / 9 удалено / 6 заполнены из названия
- `productDisplayName` 7 пропусков удалено
- `usage` 312 пропусков / большая часть, не пересекающихся с пропусками в других строках заполнены наиполее частыми категориями бренда
Остальные строки с пропусками были удалены
- `year` 1 пропуск удален
- `id` 5 строк не имели соответствующих им изображений в папке а так же по соответствующим им ссылкам из датасета `images.csv`, строки были удалены

Были сформированы и/или отредактированны так же признаки:
- `ageGroup` и `gender` содержали пересекающуюся информацию о поле и возрасте:
`gender` [`Men`, `Women`, `Unisex`, `Boys`, `Girls`]
`ageGroup` [`Adults-Men`, `Adults-Women`, `Adults-Unisex`, `Kids-Boys`, `Kids-Girls`, `Kids-Unisex`]
было решено в поле `ageGroup` оставить только информацию о возрасте [`adults`, `kids`], а в поле `gender` только о гендере [`man`, `woman`, `unisex`]
- из поля `productDisplayName` было сгенерировано два новых признака:
длинна названия `name_length` и количество слов в названии `name_word_count`, а сам признак `productDisplayName` был удалён
- На основании данных цены `price` и цены со скидкой `discountedPrice`, получен признак коэффициент скидки `discount_rate`, а цена со скидкой `discountedPrice` удалён
- получен признак популярности бренда `brand_popularity` из количества его вхождения в датасет

Были визуально проанализированы изображения:
- это фотографии товаров разной направленности
- на фото могут быть, а могут и не быть люди модели
- на всех просмотренных изображениях был белый фон
- небыло встречено никакой текстовай информации, рекламных баннеров и прочей яркой атрибутики, часто присутствующей на маркетплейсных фото товаров
- на всех фото схожее хорошее студийное освещение и хорошее качество снимков

некоторые названия колонок изменены для собственного удобства:
- `brandName` -> `brand`
- `myntraRating` -> `rating`
- `ageGroup` -> `age`
- `fashionType` -> `fashion_type`
- `baseColour` -> `color`
- `articleType` -> `article_type`
- `masterCategory` -> `category`
- `subCategory` -> `sub_category`

После предобработки датасета в нём было 44428 строк с 28 табличными признаками

## Создание прокси метрики и бинарного таргета на её основании

Для генерации матрики были использованы:
- значения весов категорий `Apparel` 1.0, `Accessories` 0.8, `Footwear` 0.7, `Personal Care` 0.5, `Free Items` 0.1, `Sporting Goods` 0.05, `Home` 0.01 (из логики частоты появления в датасете)
- значения весов сезона `Summer` 1.0, `Fall` 0.9, `Winter` 0.8, `Spring` 0.7 (из логики частоты появления в датасете)
- значения весов гендера `woman` 1.0, `unisex` 0.9, `man` 0.7 (из логики что женщины чаще любят шопинг)
- значения весов возраста `adults` 1.0, `kids` 0.8 (из логики что взрослые чаще покупают)
- длинна названия и количество слов в нём делённые на 100
- нормализованные значения `rating`, `discount_rate`, `size_availability` и `brand_popularity`с множителями 0.8, 0.1 и 0.05 для последних двух соответственно

Все эти значения просуммированы и рандомно зашумлены и записаны в промежуточный признак `success_score`. Для топ 20% по этому признаку отмечены бинарным таргетом как 1, указывающим на "успешность" товара, после чего признаки `brand_popularity` и `success_score` были удалены

## Считывание Эмбеддингов изображений

Для Эмбеддингов был выбран `CLIP "ViT-B/32"`

#### 1. Эффективность и баланс точности

Малый размер при сохранении качества. ViT-B/32 содержит около 151 млн. параметров обучена на 400 млн изображений, что делает её лёгкой в инференсе, но при этом производительной моделью CLIP превосходяъ ResNet-50 (25 млн параметров при 1.28 млн. изображений) 
[Lightly](https://www.lightly.ai/blog/clip-openai)


#### 2. Показывает хорошие показатели в сравнителььных тестах

ViT-B/32 превосходит ResNet-50 по задачам zero-shot и retrieval 
[arXiv](https://arxiv.org/html/2404.08197v1)


#### 3. Устойчивость и прочность на реальных данных

Более надежная классификация в условиях, отличных от обучающей выборки. CLIP (в том числе с ViT-B/32) проявляет устойчивость на сложных версиях ImageNet, таких как ImageNet-A 
Концентрация на общем обобщении, а не только на бенчмарке. Структура обучения CLIP (контрастивное, на веб-данных) делает его менее склонным к «читерству» на стандартных датасетах, что отражает реальную производительность модели в дикой среде 
[OpenAI](https://openai.com/index/clip/)

#### 4. Эффективные и информативные эмбеддинги

Универсальные и высокоинформативные векторные представления. Эмбеддинги CLIP подходят для сходственного поиска, кластеризации, zero-shot классификации и других сценариев

Широко признаваемая эффективность для downstream задач. ViT-модели, включая ViT-B/32, доказали способность к передаче знаний и устойчивой работе на разных задачах, особенно при больших объёмах данных 
[arXiv](https://arxiv.org/abs/2010.11929)

После извлечения эмбеддингов копия датасета сохранена как резервная, а эмбеддинги в нём переведены в строковый формат из-за особенностей сохранения датасетов `pandas`. для сохранения и загрузги датасетов с учётом конвертации в проекте используются специальные функции

## Подготовка данных к обучению

Было подготовленно три набора данных:
- Табличные данные
- Эмбеддинги
- Комбинированный набор данных их табличных и Эмбеддингов

Все три датасета разбиты на Тренировочный и тестовый датасеты с соотношениев 0.75/0.25

Датасеты с эмбеддингами предобрабатываются специальной функцией, переводящей колонку с эмбедингами в 512 колонок с отдельными векторами в соответствии с размерностью самих эмбедингов. Это необходимо для обучения выбранной модели.

Категориальные признаки кодируются с помощью `TargetEncoder`. Этот подход хорошо себя зарекомендовал в `CatBoost` модели, где он используется под капотом и решает некоторые известные проблемы других энкодеров, вроде `OneHotEncoder` или `LabelEncoder`, такие как увеличение количества признаков и замедление модели как следствие или как наделение отдельных признаков большим весом чем другие за счет их индексации [Habr](https://habr.com/ru/articles/666234)
> Обученный энкодер так же сохраняется *

## Обучение моделей

Для обучения выбран LGBMClassifier. Так как задача стояла сравнить результаты на разных наборах данных, а не выбрать лучшую модель, я сравнивал наборы данных только на одной модели и взял по моему опыту хорошую модель, показывающую в других моих тестах хорошие результаты и удобство работы с ней. Но не буду ссылатся только на свой опыт, вот ещё аргументы:

#### 1. Высокая точность и производительность

LightGBM (LGBM) основан на градиентном бустинге по деревьям решений, который считается одним из лучших алгоритмов для табличных данных

В ряде сравнительных исследований LGBM показывает лучшие результаты или сопоставимые с XGBoost и CatBoost, но при этом работает быстрее за счёт оптимизаций [Ke et al., 2017](https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html)

#### 2. Эффективность на больших данных

LGBM использует Histogram-based алгоритм и метод Gradient-based One-Side Sampling (GOSS), что позволяет обучаться на миллионах объектов быстрее и с меньшим потреблением памяти

Для реальных индустриальных задач (e-commerce, рекомендательные системы) это даёт возможность работать с большими датасетами, не жертвуя скоростью

#### 3. Работа с эмбеддингами

LGBM отлично подходит для работы с плотными векторными признаками (например, эмбеддингами CLIP), так как он умеет выявлять нелинейные зависимости и взаимодействия между признаками без явного инженеринга

В отличие от линейных моделей, LGBM способен уловить сложные структуры данных, что критично для изображений, конвертированных в эмбеддинги

#### 4. Интерпретируемость

Модель предоставляет оценку важности признаков (feature importance), что полезно для анализа вклада различных компонент эмбеддинга или дополнительных табличных фич (цена, категория, брэнд)

#### 5. Устойчивость и стабильность

LGBM хорошо работает даже при шумных признаках и частичных пропусках

Использует регуляризацию и контроль глубины деревьев, что помогает избежать переобучения

Сравнение с альтернативами
| Модель        | Плюсы                                                                                | Минусы                                            |
| ------------- | ------------------------------------------------------------------------------------ | ------------------------------------------------- |
| **LGBM**      | Быстрая, точная, хорошо работает с эмбеддингами и большими данными, интерпретируемая | Иногда требует тонкой настройки гиперпараметров   |
| **XGBoost**   | Классический стандарт, очень устойчив                                                | Более медленный, требует больше ресурсов          |
| **CatBoost**  | Отличная работа с категориальными фичами «из коробки»                                | Дольше обучается, иногда хуже масштабируется      |
| **Нейросети** | Можно дообучать эмбеддинги, высокая гибкость                                         | Требует больших ресурсов, хуже интерпретируемость |

> Тонкая настройка гиперпараметров проводилась с помощью `RandomizedSearchCV`, плюс работы с категориальными признаками из CatBoost мы так же переняли используя `TargetEncoder`

LGBM выбран как оптимальный компромисс между качеством, скоростью и интерпретируемостью

Для поиска оптимальных параметров был использован `RandomizedSearchCV` на кроссвалидации `KFold` с параметром `n_splits=5`. Случайный перебор был выбран как хороший компромис между качество и скоростью по сравнению с  `GridSearchCV`, но если будет требоватся не сравнительный тест, а подготовка прод модели, этот подход проигрывает в качестве и лучше пожертвовать временем наболее качественный подход для поиска гиперпараметров

## Анализ результатов

| Модель      | Лучшая ROC-AUC | F1 при лучшей ROC-AUC | Лучшая F1 | ROC-AUC при лучшей F1 |
|-------------|----------------|------------------------|-----------|-----------------------|
| FullData    | 0.8615         | 0.5765                 | 0.5867    | 0.8526                |
| TabData     | 0.8646         | 0.5785                 | 0.5785    | 0.8645                |
| Embbadings  | 0.8213         | 0.5546                 | 0.5594    | 0.8195                |

Табличные данные показали наилучшие показатели на кросс-валидации.

На тренировочных данных с использованием обученных на данных моделях были построены ROC-кривые
![ROC-кривые моделей](images\full_curve.png)
На криывх видно что не смотря на плохие показатели на кросс-валидации, тут модель на эмбеддингах показывает результаты лучше и при этом рисует странную по форме кривую. это результат переобучения модели, на самом деле она хуже по качеству и показатели на кросс валидации это более объективные показатели

## Тестирование модели

Тестирование модели на тестовых данных проводилось только на табличных данных, так как анализ результатов показал что этот подход лучше

Были использованы гиперпараметры, найденные с помощью `RandomizedSearchCV`, а именно `num_leaves`=38, `n_estimators`=1000, `max_depth`=1, `learning_rate`=0.14

#### ROC-кривая теста
![ROC-кривая теста](images\test_curve.png)

> F1 на тестовой выборке: 0.6082

#### Важность признаков
![Важность признаков](images\f_importance.png)

Наиболее повлиявшие на предсказание признаки:
- бренд
- категория
- цена
- гендер
- сезон

#### Матрица ошибок
![Матрица ошибок](images\mx.png)

Модель чаще ошибается в False Negative, это связано с дисбалансов класса `Target`, это стоит учесть в случае работы над увеличением точности предсказаний

## Кластеризация

![Кластеризация](images\Clasterization.png)

1. Оптимальное число кластеров

Метод локтя → чёткой «точки излома» нет, инерция плавно снижается
- Silhouette Score → максимум при k = 6
- структура данных не идеально кластеризуется KMeans (силуэт низкий: ~0.12), но 6 кластеров — лучший компромисс

2. Размеры кластеров
- Кластеры получились достаточно сбалансированные: от ~1900 (кластер 1) до ~6900 (кластер 3)
- Нет явно доминирующего или крошечного кластера
- каждый кластер репрезентативен, есть смысл анализировать различия

3. Успешность по кластерам (target)
- Средняя доля успешных товаров ≈ 0.20.
- кластер 4 (0.215),
- кластер 5 (0.202).
- кластер 3 (0.186),
- кластер 1 (0.192).
- товары из кластеров 4 и 5 немного успешнее, но не на столько, чтобы можно было сказать что какие либо кластеры более успешны, соотношение такое же как и во всём датасете

4. PCA-визуализация
- На 2D-проекции видно относительно хорошо разделённые «пятна» для разных кластеров, но есть и перекрытия, что отражает невысокий силуэтный коэффициент
- данные имеют не идеально чёткие границы, но выделяются локальные плотности.

5. Распределение признаков по кластерам
- Категории равномерно распределены по всем кластерам
- Пол и Возраст тоже не выделяются в разные кластеры
- бренд тоже выглядит как заполненные вертикальные линии и не видно смысла глубоко всматриватся в этот параметр
- Небольшое преобладание голубого цвета есть во втором кластеризуется
- В целом сложно сказать что какой то из признаков может отвечать за эти кластеры

## Итоговый вывод
- Обучение модели на исключительно табличных признаках показало результаты лучше, изображения в данном случае только ухудшают результат.
Связано это с тем что мы используем синтетическую метрику, сформированную из табличных данных и никак не связанную с однотипными изображениями датасета
- Модель KMeans с k=6 выявила группы товаров
- Кластеры слабо отличающиеся по успешности (максимум +3% к "успешности")
- Silhouette score низкий
- возможно имеет смысл попробовать использовать эти кластеры как фичи, но это не входило в планы этого проекта, а так же вероятность подтверждения этой гипотезы мала
- Есть предположение что изображения в датасете очень похожи по своему типажу, все на белом фоне, только товар, нет надписей, студийных фото с красивым цветом или ярких элементом и информации на них, например про скидки. Если бы мы оценивали фото с реальных маркетплейсов и на реальных метриках CTR, то там бы влияние фото было бы заметнее
